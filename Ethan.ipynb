{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYlaRwNu7ojq"
   },
   "source": [
    "# **Homework 2-1 Phoneme Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emUd7uS7crTz"
   },
   "source": [
    "## The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\n",
    "The TIMIT corpus of reading speech has been designed to provide speech data for the acquisition of acoustic-phonetic knowledge and for the development and evaluation of automatic speech recognition systems.\n",
    "\n",
    "This homework is a multiclass classification task, \n",
    "we are going to train a deep neural network classifier to predict the phonemes for each frame from the speech corpus TIMIT.\n",
    "\n",
    "link: https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVUGfWTo7_Oj"
   },
   "source": [
    "## Download Data\n",
    "Download data from google drive, then unzip it.\n",
    "\n",
    "You should have `timit_11/train_11.npy`, `timit_11/train_label_11.npy`, and `timit_11/test_11.npy` after running this block.<br><br>\n",
    "`timit_11/`\n",
    "- `train_11.npy`: training data<br>\n",
    "- `train_label_11.npy`: training label<br>\n",
    "- `test_11.npy`:  testing data<br><br>\n",
    "\n",
    "**notes: if the google drive link is dead, you can download the data directly from Kaggle and upload it to the workspace**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzkiMEcC3Foq",
    "outputId": "4308c64c-6885-4d1c-8eb7-a2d9b8038401"
   },
   "outputs": [],
   "source": [
    "# !gdown --id '1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR' --output data.zip\n",
    "# !unzip data.zip\n",
    "# !ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L_4anls8Drv"
   },
   "source": [
    "## Preparing Data\n",
    "Load the training and testing data from the `.npy` file (NumPy array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJjLT8em-y9G",
    "outputId": "8edc6bfe-7511-447f-f239-00b96dba6dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Size of training data: (1229932, 429)\n",
      "Size of testing data: (451552, 429)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Loading data ...')\n",
    "\n",
    "data_root='./timit_11/'\n",
    "train = np.load(data_root + 'train_11.npy')\n",
    "train_label = np.load(data_root + 'train_label_11.npy')\n",
    "test = np.load(data_root + 'test_11.npy')\n",
    "\n",
    "\n",
    "print('Size of training data: {}'.format(train.shape))\n",
    "print('Size of testing data: {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_11.npy  train_11.npy  train_label_11.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls timit_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1229932, 39, 11)\n",
      "(451552, 39, 11)\n",
      "[[-1.06118095e+00 -1.06031787e+00 -1.06123281e+00 -1.06212807e+00\n",
      "  -1.06191611e+00 -1.05042028e+00 -9.55076098e-01 -8.40701520e-01\n",
      "  -7.30128646e-01 -5.20460784e-01 -3.11334819e-01]\n",
      " [-8.29701960e-01 -8.63627851e-01 -9.03625906e-01 -9.08962548e-01\n",
      "  -9.70546961e-01 -1.06862378e+00 -1.58940804e+00 -1.81785882e+00\n",
      "  -2.06564474e+00 -2.21396041e+00 -2.19305611e+00]\n",
      " [ 1.03218007e+00  1.22968948e+00  9.42397118e-01  9.75875378e-01\n",
      "   9.24154639e-01  5.58611751e-01  6.16136611e-01  4.85490590e-01\n",
      "   1.86883658e-01  4.54778820e-01  5.83996654e-01]\n",
      " [-3.63739356e-02  7.56692290e-02 -3.81120890e-02 -2.04413667e-01\n",
      "   1.46834910e-01  1.10776991e-01  1.71702251e-01 -2.02655718e-01\n",
      "  -3.65922928e-01  1.37009159e-01 -1.15972005e-01]\n",
      " [ 1.44260001e+00  1.48449290e+00  1.65353727e+00  1.22211385e+00\n",
      "   9.20319498e-01  7.71914423e-01  4.44531530e-01  4.21492569e-02\n",
      "  -9.96498689e-02 -2.36613244e-01 -8.38180006e-01]\n",
      " [ 1.15673923e+00  1.45324707e+00  1.22543192e+00  9.93508041e-01\n",
      "   1.27266622e+00  1.23919809e+00  1.52057469e+00  1.01531172e+00\n",
      "   1.35353315e+00  9.44357753e-01  1.16305590e+00]\n",
      " [ 1.65909684e+00  1.57720077e+00  1.17685366e+00  8.76231849e-01\n",
      "   1.16062248e+00  9.80679393e-01 -4.31532651e-01 -7.92341292e-01\n",
      "  -6.90742791e-01  1.86723739e-01  3.92338574e-01]\n",
      " [ 1.26991653e+00  1.08029580e+00  1.33255804e+00  1.43398941e+00\n",
      "   1.58957672e+00  1.36081409e+00  1.94033718e+00  9.33648705e-01\n",
      "   6.87243164e-01  7.26103544e-01  9.73371744e-01]\n",
      " [ 1.29599738e+00  1.22445810e+00  1.31299901e+00  1.26532602e+00\n",
      "   1.30237186e+00  1.39392006e+00  1.16426265e+00  1.37912941e+00\n",
      "   1.03387594e+00  4.23629843e-02  8.21318984e-01]\n",
      " [ 9.63423610e-01  9.57690656e-01  1.70436823e+00  1.97007048e+00\n",
      "   1.73544633e+00  1.31515992e+00  3.38921487e-01  1.48887157e+00\n",
      "   1.27258444e+00  5.93997777e-01  5.63197315e-01]\n",
      " [ 6.44926846e-01  6.89464390e-01  7.87518263e-01  8.72867465e-01\n",
      "   6.06748164e-01  9.11246061e-01  2.47822583e-01  1.05156589e+00\n",
      "   2.01744223e+00  2.75454700e-01  1.32885087e+00]\n",
      " [ 8.45081031e-01  1.33886659e+00  1.29268754e+00  1.13416886e+00\n",
      "   1.19970751e+00  1.64093864e+00  6.99799240e-01  5.91378033e-01\n",
      "   1.35738683e+00  8.02780032e-01  1.42390704e+00]\n",
      " [ 3.42684537e-01  5.69743216e-01  3.90054166e-01  9.52655673e-02\n",
      "  -9.32869986e-02  5.70503831e-01  9.47623327e-02 -9.78660524e-01\n",
      "   5.79804406e-02  1.43263817e-01 -8.61321390e-01]\n",
      " [ 5.10036480e-04  4.01845528e-03  4.01581302e-02  1.07997186e-01\n",
      "   1.95697382e-01  3.28374028e-01  4.87677306e-01  6.59198225e-01\n",
      "   7.70361304e-01  7.54907012e-01  5.14843047e-01]\n",
      " [-2.12455932e-02 -6.46719337e-02 -3.37548256e-01 -7.28254497e-01\n",
      "  -1.02887332e+00 -1.24639738e+00 -1.32175124e+00 -1.27271903e+00\n",
      "  -1.05683970e+00 -6.56272054e-01 -2.91104317e-02]\n",
      " [ 2.14666456e-01  2.17502117e-01  2.88712144e-01 -9.91247073e-02\n",
      "  -5.98904252e-01 -5.96226037e-01 -3.98572385e-01 -4.07840222e-01\n",
      "  -4.84485388e-01 -3.51282090e-01 -3.69456559e-01]\n",
      " [ 1.67591404e-02  1.78295150e-02  5.72003759e-02  2.07148567e-02\n",
      "  -1.37208074e-01 -6.02521524e-02 -5.11770137e-02  9.65095460e-02\n",
      "  -5.23381233e-02  2.79432535e-01  5.72675049e-01]\n",
      " [-5.36807537e-01 -8.39905918e-01 -1.20687795e+00 -1.30949616e+00\n",
      "  -1.25656593e+00 -1.40948248e+00 -1.61139297e+00 -1.42963982e+00\n",
      "  -1.40884960e+00 -1.12508857e+00 -6.58208549e-01]\n",
      " [-1.16773151e-01 -1.12149477e-01  2.86794603e-02 -4.99211997e-02\n",
      "   2.71264520e-02 -1.32102206e-01 -4.61830273e-02 -2.03768626e-01\n",
      "  -2.74756432e-01 -2.76002973e-01 -5.55097759e-01]\n",
      " [-7.11902827e-02  1.06648453e-01 -1.50001183e-01 -1.00952947e+00\n",
      "  -1.69064796e+00 -1.38518500e+00 -9.16405618e-01 -6.18606389e-01\n",
      "  -1.50329188e-01  3.25811177e-01  9.18861151e-01]\n",
      " [ 4.85284552e-02  3.63196172e-02  4.05286580e-01  1.94749400e-01\n",
      "  -1.70910954e-01 -4.29135561e-01 -6.23762488e-01 -8.28281641e-01\n",
      "  -9.15076315e-01 -1.03030431e+00 -9.11956489e-01]\n",
      " [-1.01121791e-01 -2.14937463e-01 -2.98659265e-01 -6.08527362e-02\n",
      "  -9.75871682e-02 -6.18704140e-01 -6.97170138e-01 -7.22793996e-01\n",
      "  -6.52323902e-01 -1.13547254e+00 -1.30992973e+00]\n",
      " [ 2.42028251e-01  1.75648510e-01 -2.33184099e-01 -1.24126054e-01\n",
      "  -6.77761510e-02 -5.11061788e-01 -9.33167636e-01 -6.49429500e-01\n",
      "  -4.12303478e-01 -1.36951849e-01 -5.83235174e-03]\n",
      " [-6.44814000e-02  6.59720674e-02 -1.76584348e-01  1.82864871e-02\n",
      "   5.19630373e-01  2.03825504e-01  3.21253061e-01  4.07665446e-02\n",
      "  -3.56568009e-01 -7.08771884e-01 -5.07001519e-01]\n",
      " [-1.34661481e-01  1.56778574e-01 -5.45328893e-02 -2.59372294e-01\n",
      "  -6.05026260e-02 -3.05523515e-01 -9.09742936e-02  6.35120124e-02\n",
      "   7.45925829e-02  5.15467077e-02  3.79579306e-01]\n",
      " [-2.01623127e-01  2.20319703e-01  2.21217513e-01 -3.81689548e-01\n",
      "  -5.24223149e-01 -4.12613809e-01 -5.43052495e-01 -5.95824838e-01\n",
      "  -4.82759655e-01 -7.88462102e-01 -3.61937255e-01]\n",
      " [-2.89866375e-03  7.37798680e-03  9.45613980e-02  2.12639257e-01\n",
      "   3.04244697e-01  4.25035417e-01  4.98073280e-01  5.01842797e-01\n",
      "   3.02662909e-01 -1.14774883e-01 -7.85685897e-01]\n",
      " [-7.81967863e-02 -2.85231531e-01 -8.27450037e-01 -8.58649135e-01\n",
      "  -8.74331117e-01 -6.60828531e-01 -1.17573440e-01  5.02664506e-01\n",
      "   9.80262697e-01  1.24326789e+00  1.24015629e+00]\n",
      " [ 3.94878179e-01 -3.70392859e-01 -1.13819194e+00 -8.64577234e-01\n",
      "  -2.71221966e-01  1.34227246e-01  3.20442975e-01  2.97489703e-01\n",
      "  -7.49856308e-02 -1.17138013e-01 -2.78456789e-02]\n",
      " [-4.70134839e-02  1.88651308e-01  3.90801787e-01 -1.14494510e-01\n",
      "  -4.47424710e-01 -3.75178345e-02 -1.50099874e-01  2.53030598e-01\n",
      "   3.80662113e-01  7.76109815e-01  7.70842195e-01]\n",
      " [-8.95984828e-01 -6.14090145e-01 -6.28362969e-02 -2.61136711e-01\n",
      "  -5.76478779e-01 -8.73855799e-02  4.89678280e-03  1.71916321e-01\n",
      "   1.39069304e-01  7.18606234e-01  1.13364911e+00]\n",
      " [-6.28345683e-02  6.02679923e-02  3.03181887e-01  2.57611321e-03\n",
      "   5.36577478e-02 -8.24022889e-02 -2.39009365e-01 -5.39968312e-01\n",
      "  -1.96973234e-02  1.40111014e-01 -2.09791645e-01]\n",
      " [ 5.07550836e-01 -1.31131560e-01 -1.99815810e+00 -1.90944779e+00\n",
      "  -6.34124517e-01  4.75858897e-01  1.23354352e+00  1.48270547e+00\n",
      "   1.94967616e+00  1.05625045e+00 -1.97946578e-01]\n",
      " [ 4.15173382e-01  3.97200704e-01  4.66274470e-01 -3.64855826e-01\n",
      "  -8.76622081e-01 -9.94346380e-01 -3.86144102e-01 -1.09128229e-01\n",
      "   2.28254318e-01  8.91476497e-02  6.05132818e-01]\n",
      " [-2.36231297e-01  2.25695267e-01  3.12472910e-01  1.56460822e-01\n",
      "  -1.75224483e-01 -9.29976285e-01 -4.77330923e-01 -1.29797742e-01\n",
      "   3.60403627e-01 -2.61040270e-01 -4.22132939e-01]\n",
      " [ 6.68047249e-01  2.12702885e-01 -8.77222955e-01 -5.57713985e-01\n",
      "  -6.45301938e-01 -5.92114508e-01  7.68109113e-02  8.80621135e-01\n",
      "   5.24278343e-01  1.09594189e-01 -2.53685057e-01]\n",
      " [ 1.05560618e-02  1.56177590e-02 -1.82582885e-01  6.92279488e-02\n",
      "   6.59369946e-01 -5.11203669e-02  1.28474668e-01 -4.71850932e-01\n",
      "  -1.13539720e+00 -9.99418020e-01 -2.63690263e-01]\n",
      " [ 2.39964873e-01  3.26819539e-01 -2.33716592e-01 -5.68377793e-01\n",
      "  -3.00959140e-01 -2.72168573e-02  3.91026318e-01  4.87448245e-01\n",
      "   4.35466647e-01  1.70763090e-01 -4.16162431e-01]\n",
      " [ 2.05573156e-01 -2.06116382e-02 -4.03018534e-01 -8.28798473e-01\n",
      "  -7.39374831e-02  3.60568106e-01 -9.63936597e-02 -2.49728322e-01\n",
      "   1.69133261e-01  1.03426144e-01  1.44490823e-01]]\n"
     ]
    }
   ],
   "source": [
    "train = train.reshape(train.shape[0], 11, 39)\n",
    "test = test.reshape(test.shape[0], 11, 39)\n",
    "train = np.swapaxes(train,1,2)\n",
    "test = np.swapaxes(test,1,2)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "us5XW_x6udZQ"
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fjf5EcmJtf4e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TIMITDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = torch.from_numpy(X).float()\n",
    "        if y is not None:\n",
    "            y = y.astype(int)\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otIC6WhGeh9v"
   },
   "source": [
    "Split the labeled data into a training set and a validation set, you can modify the variable `VAL_RATIO` to change the ratio of validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYqi_lAuvC59",
    "outputId": "13dabe63-4849-47ee-fe04-57427b9d601c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: (983945, 39, 11)\n",
      "Size of validation set: (245987, 39, 11)\n"
     ]
    }
   ],
   "source": [
    "VAL_RATIO = 0.2\n",
    "\n",
    "percent = int(train.shape[0] * (1 - VAL_RATIO))\n",
    "train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n",
    "print('Size of training set: {}'.format(train_x.shape))\n",
    "print('Size of validation set: {}'.format(val_x.shape))\n",
    "train_size = train_x.shape[0]\n",
    "val_size = val_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbCfclUIgMTX"
   },
   "source": [
    "Create a data loader from the dataset, feel free to tweak the variable `BATCH_SIZE` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RUCbQvqJurYc"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = TIMITDataset(train_x, train_y)\n",
    "val_set = TIMITDataset(val_x, val_y)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SY7X0lUgb50"
   },
   "source": [
    "Cleanup the unneeded variables to save memory.<br>\n",
    "\n",
    "**notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later<br>the data size is quite huge, so be aware of memory usage in colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8rzkGraeYeN",
    "outputId": "dc790996-a43c-4a99-90d4-e7928892a899"
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# del train, train_label, train_x, train_y, val_x, val_y\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRqKNvNZwe3V"
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYr1ng5fh9pA"
   },
   "source": [
    "Define model architecture, you are encouraged to change and experiment with the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lbZrwT6Ny0XL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(39, 31, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(31 * 9, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 39)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(\"initial shape: \", x.shape)\n",
    "        x = self.conv(x)\n",
    "#         print(\"after convolution: \", x.shape)\n",
    "        x = torch.flatten(x, start_dim = 1)\n",
    "#         print(\"after flatten: \", x.shape)\n",
    "        x = self.fc(x)\n",
    "#         print(\"final: \", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRYciXZvPbYh"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "y114Vmm3Ja6o"
   },
   "outputs": [],
   "source": [
    "#check device\n",
    "def get_device():\n",
    "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEX-yjHjhGuH"
   },
   "source": [
    "Fix random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "88xPiUnm0tAd"
   },
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbBcBXkSp6RA"
   },
   "source": [
    "Feel free to change the training parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QTp3ZXg1yO9Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "same_seeds(0)\n",
    "\n",
    "# get device \n",
    "device = get_device()\n",
    "print(f'DEVICE: {device}')\n",
    "\n",
    "# training parameters\n",
    "num_epoch = 20               # number of training epoch\n",
    "learning_rate = 0.0001       # learning rate\n",
    "\n",
    "# the path where checkpoint saved\n",
    "model_path = './model.ckpt'\n",
    "\n",
    "# create model, define a loss function, and optimizer\n",
    "model = Classifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdMWsBs7zzNs",
    "outputId": "c5ed561e-610d-4a35-d936-fd97adf342a0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195f2b2a1a204dbfb5e3eb189a8cfcbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affac37c4efd4f2d8a840976dcd19694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start training\n",
    "from tqdm.notebook import tqdm\n",
    "best_acc = 0.0\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train() # set the model to training mode\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(inputs) \n",
    "        \n",
    "        if i == 0:\n",
    "            print(\"inputs: \", inputs.shape)\n",
    "            print(\"output: \", outputs.shape)\n",
    "            print(\"Labels: \", labels.shape)\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "#             print(\"loss: \", batch_loss)\n",
    "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "        batch_loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "    # validation\n",
    "    if len(val_set) > 0:\n",
    "        model.eval() # set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(val_loader)):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                 print(\"inputs: \", inputs.shape)\n",
    "#                 print(\"Labels: \", labels.shape)\n",
    "                outputs = model(inputs)\n",
    "#                 print(\"output: \", outputs.shape)\n",
    "                batch_loss = criterion(outputs, labels) \n",
    "                _, val_pred = torch.max(outputs, 1) \n",
    "            \n",
    "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
    "                val_loss += batch_loss.item()\n",
    "\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
    "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
    "            ))\n",
    "\n",
    "            # if the model improves, save a checkpoint at this epoch\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
    "    else:\n",
    "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
    "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
    "        ))\n",
    "\n",
    "# if not validating, save the last epoch\n",
    "if len(val_set) == 0:\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print('saving model at last epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Hi7jTn3PX-m"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfUECMFCn5VG"
   },
   "source": [
    "Create a testing dataset, and load model from the saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PKjtAScPWtr",
    "outputId": "8c17272b-536a-4692-a95f-a3292766c698"
   },
   "outputs": [],
   "source": [
    "# create testing dataset\n",
    "test_set = TIMITDataset(test, None)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# create model and load weights from checkpoint\n",
    "model = Classifier().to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "940TtCCdoYd0"
   },
   "source": [
    "Make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84HU5GGjPqR0"
   },
   "outputs": [],
   "source": [
    "predict = []\n",
    "model.eval() # set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs = data\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "\n",
    "        for y in test_pred.cpu().numpy():\n",
    "            predict.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWDf_C-omElb"
   },
   "source": [
    "Write prediction to a CSV file.\n",
    "\n",
    "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuljYSPHcZir"
   },
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(predict):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SHARE MLSpring2021 - HW2-1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
